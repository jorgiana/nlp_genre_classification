{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6ea24-566a-4fb9-9a04-1bbe6f9067eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from utils import Attention\n",
    "from keras.layers import Embedding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a7c84-510a-4ebd-baa0-5cc555ac35dd",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362ba2f-0909-4f78-a3d6-e0e3b1667341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-lyrics.csv')\n",
    "test_df = pd.read_csv('test-lyrics.csv')\n",
    "\n",
    "joined_genres = pd.concat([df['genre'], test_df['genre']]).reset_index(drop=True)\n",
    "cat_labels = []\n",
    "for genre in joined_genres:\n",
    "    if genre == \"country\": cat_labels.append(0)\n",
    "    elif genre == \"pop\": cat_labels.append(1)\n",
    "    elif genre == \"r-b\": cat_labels.append(2)\n",
    "    elif genre == \"rock\": cat_labels.append(3)\n",
    "    elif genre == \"rap\": cat_labels.append(4)\n",
    "\n",
    "texts = pd.concat([df['input texts'], test_df['input texts']]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d469db0e-1092-4adb-afe2-2b0ce0339a0b",
   "metadata": {},
   "source": [
    "# Loading in Pre-trained Word Vectors (GLoVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f275d4-6f49-4974-8c5b-132249756643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(file):\n",
    "    \n",
    "    f = open(file, 'r', encoding='utf8')\n",
    "    glove_model = {}\n",
    "    \n",
    "    for line in f:\n",
    "        split_lines = line.split()\n",
    "        if len(split_lines) > 1:\n",
    "            word = split_lines[0]\n",
    "            word_embedding = np.array([float(value) for value in split_lines[1:]])\n",
    "            \n",
    "            glove_model[word] = word_embedding\n",
    "    \n",
    "    print(len(glove_model), \" words loaded\")\n",
    "    return glove_model\n",
    "\n",
    "glove_path = '../glove.6B.200d.txt'\n",
    "\n",
    "glove_pretrained = load_glove(glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d364caf-5607-4411-b01f-3130f3be4f7b",
   "metadata": {},
   "source": [
    "## Creating Vocabulary and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51615733-4324-475b-a027-3a16d863fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 200\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS, \n",
    "                      filters='â€™()``''')\n",
    "\n",
    "# Create vocabulary from lyrics data\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "vocab_size = len(word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8fca3-1a2b-40e5-bf5c-772ebbf6c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "# Creating our data matrix\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# Creating label matrix \n",
    "labels = tf.keras.utils.to_categorical(cat_labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f9658-bfff-420c-9630-8d087a8e03c0",
   "metadata": {},
   "source": [
    "### Creating Embedding Matrix from GLoVE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b302b7d-2239-47b8-819b-1c63f8fcd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bec2fd-3b71-4bc8-9ed6-3aa712526f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating our embeddings matrix \n",
    "\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "embeddings_matrix = np.zeros((vocab_size + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = glove_pretrained.get(word)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        if embedding_vector is not None:\n",
    "            \n",
    "            embeddings_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        \n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640a5f9-56fb-40d6-9bad-ddba5c84fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[embeddings_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b20b95-f094-4b3b-a214-53a0764efb12",
   "metadata": {},
   "source": [
    "# Data Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e37f6b-a795-472e-8b45-ab7546530dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, \n",
    "                                                    labels,\n",
    "                                                    stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec61216-86c3-4e18-8ae4-7dbecb4f46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5acb3-da7d-41d1-9ec2-3d668d69fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3c473-6599-421d-9ad2-e4c108a8a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d70a5f-e96b-4e40-94ae-0d617964d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = y_train.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57874f-d589-40d2-9c00-1dc13dbcc076",
   "metadata": {},
   "source": [
    "# Baseline Model 1 - LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a8fd2-9276-4dfe-8dfd-309cc87176d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(rnn_units=200,\n",
    "                 optimizer=tf.keras.optimizers.Adam(), \n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                 metrics=[\"accuracy\"]):\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding_layer = Embedding(vocab_size + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            weights=[embeddings_matrix], \n",
    "                            input_length=MAX_SEQUENCE_LENGTH, \n",
    "                            trainable=False, \n",
    "                            name=\"embedding_layer\") \n",
    "    \n",
    "    sequence_input = layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "                                  dtype=\"int32\", \n",
    "                                  name=\"input layer\")\n",
    "    \n",
    "    embeddings = embedding_layer(sequence_input)\n",
    "    \n",
    "    rnn_output = layers.LSTM(rnn_units,\n",
    "                             name=\"LSTM\")(embeddings)\n",
    "    \n",
    "    output = layers.Dense(num_labels, \n",
    "                          activation=\"softmax\", \n",
    "                          name=\"output_layer\")(rnn_output)\n",
    "    \n",
    "    model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=loss, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa79fce-bdda-4b26-92da-2fe803233318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_training_df(history_dict, num_epochs):\n",
    "    epochs_index = pd.Index(data=list(range(1, num_epochs + 1)), name=\"epoch\")\n",
    "    out_df = pd.DataFrame(history_dict).set_index(epochs_index)\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "def plot_model_performance(df, model_name):\n",
    "    \n",
    "    df_one = df[['loss', 'val_loss']]\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.lineplot(data=df_one)\n",
    "    plt.title(model_name + \" Loss by Epochs\");\n",
    "    plt.show();\n",
    "    \n",
    "    df_two = df[['accuracy', 'val_accuracy']]\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.lineplot(data=df_two)\n",
    "    plt.title(model_name + \" Accuracy by Epochs\");\n",
    "    plt.show();\n",
    "    \n",
    "    \n",
    "def evaluate_model(model):\n",
    "    \n",
    "    return model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5b835-3dcc-4332-95ff-1f885dc70ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(create_fn):\n",
    "    \n",
    "    model = create_fn()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=10, \n",
    "                        batch_size=20, \n",
    "                        validation_data=(X_test, y_test),\n",
    "                        verbose=1)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7b842-945c-438c-9b6d-6337a009bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_one, history = fit_model(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e3eec-46a3-462d-94eb-d74b222b2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one_history_df = create_model_training_df(history.history, 10)\n",
    "plot_model_performance(model_one_history_df, \"LSTM Baseline Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fd5d3-f4ec-4566-b63c-7c8ba5c7f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_one.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f0cab-351f-4128-82f7-3938052f6908",
   "metadata": {},
   "source": [
    "# Improving Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c5066-cad9-4b94-a3bd-3b4a4c722b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_imp(rnn_units=200,\n",
    "                 optimizer=tf.keras.optimizers.Adam(), \n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                 metrics=[\"accuracy\"]):\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding_layer = Embedding(vocab_size + 1, \n",
    "                            EMBEDDING_DIM, \n",
    "                            weights=[embeddings_matrix], \n",
    "                            input_length=MAX_SEQUENCE_LENGTH, \n",
    "                            trainable=True) # Changed weights to be trainable \n",
    "    \n",
    "    sequence_input = layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "                                  dtype=\"int32\")\n",
    "    \n",
    "    embeddings = embedding_layer(sequence_input)\n",
    "    \n",
    "    rnn_output = layers.LSTM(rnn_units)(embeddings)\n",
    "    \n",
    "    dropout = layers.Dropout(0.5)(rnn_output) # Added a dropout layer to reduce overfitting \n",
    "    \n",
    "    output = layers.Dense(num_labels, \n",
    "                          activation=\"softmax\")(dropout)\n",
    "    \n",
    "    model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=loss, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ef3c6-3113-480c-b9c1-b6c753d8cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_one, improved_model_one_history = fit_model(create_model_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87aecd9-56d0-48a8-97d3-f1f6f3a24f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_history_df = create_model_training_df(improved_model_one_history.history, 10)\n",
    "plot_model_performance(improved_model_history_df, \"LSTM Model (trainable weights)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09532d1d-f395-48d2-ad94-7310ec964183",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_one.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db133b93-108f-4c84-b537-bf5aa17b6953",
   "metadata": {},
   "source": [
    "# Improving Model 1 Pt. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349cf9f-be5d-4401-93b5-6c6f989a1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_impt_pt2(rnn_units=200,\n",
    "                 optimizer=tf.keras.optimizers.Adam(), \n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                 metrics=[\"accuracy\"]):\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding_layer = Embedding(vocab_size + 1, \n",
    "                                EMBEDDING_DIM, \n",
    "                                weights=[embeddings_matrix], \n",
    "                                input_length=MAX_SEQUENCE_LENGTH, \n",
    "                                trainable=True) \n",
    "    \n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "                                  dtype=\"int32\"))\n",
    "    \n",
    "    model.add(embedding_layer)\n",
    "    \n",
    "    model.add(layers.LSTM(rnn_units,\n",
    "                          return_sequences=True))\n",
    "    \n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.LSTM(rnn_units)    # Added a second LSTM layer\n",
    "    \n",
    "    model.add(layers.Dropout(0.5)) # And a second dropout layer\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(num_labels,\n",
    "                           activation=\"softmax\"))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=loss, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf25d1a-b726-4251-9633-06e0268daddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_one_pt2, improved_model_one_pt2_history = fit_model(create_model_impt_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81609b-fa11-404e-83e5-0f4c3329275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_pt2_history_df = create_model_training_df(improved_model_one_pt2_history.history, 10)\n",
    "plot_model_performance(improved_model_pt2_history_df, \"Stacked LSTM Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbabf84-4c5a-4e45-a266-4d55e65353dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_one_pt2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e36689-2693-4d76-9727-fc58250a383e",
   "metadata": {},
   "source": [
    "# Improving Model 1 Pt. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e60f7-ad4d-4d0b-bd4a-dcf8cc801b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pt3(rnn_units=200,\n",
    "                     a_units=200, \n",
    "                     optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=[\"accuracy\"]):\n",
    "    \n",
    "    sequence_input = layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "                                  dtype=\"int32\")\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding_layer = Embedding(vocab_size + 1, \n",
    "                                EMBEDDING_DIM, \n",
    "                                weights=[embeddings_matrix], \n",
    "                                input_length=MAX_SEQUENCE_LENGTH, \n",
    "                                trainable=True)(sequence_input) \n",
    "    \n",
    "    lstm_out, hidden_h, hidden_c = layers.LSTM(rnn_units, \n",
    "                                               name=\"LSTM\", \n",
    "                                               return_sequences=True, \n",
    "                                               return_state=True)(embedding_layer)\n",
    "    \n",
    "    \n",
    "    x, attn_weights = Attention(a_units)(lstm_out, hidden_h)\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(50)(x)\n",
    "    \n",
    "    \n",
    "    output = layers.Dense(num_labels,\n",
    "                          activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=loss, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643304be-b195-482e-a573-2ba872c98089",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_pt3, improved_model_pt3_history = fit_model(create_model_pt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2d8d7-12f1-456e-b113-6d4e237fe15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_pt3_df = create_model_training_df(improved_model_pt3_history.history, 10)\n",
    "plot_model_performance(improved_model_pt3_df, \"LSTM Model (w Attention)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14de53-b448-4c32-a19a-d5ce2bf46323",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(improved_model_pt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc28530-13ed-458a-9f92-da46dcad077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = improved_model_pt3.predict(X_test)\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "genre_lst = [\"country\", \"pop\", \"r-b\", \"rock\", \"rap\"]\n",
    "\n",
    "sns.heatmap(cm, cmap=\"Blues\", \n",
    "            xticklabels=genre_lst, \n",
    "            yticklabels=genre_lst)\n",
    "\n",
    "plt.title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92432720-0553-4169-8057-8dd0488f10da",
   "metadata": {},
   "source": [
    "# Comparing all versions of Model 1\n",
    "\n",
    "## Baseline Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164800d-e1bc-43d6-8844-ab845486b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(baseline_model_one, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b78500-372f-4774-8cc0-1780fc5dbc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_one.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd96557-0c71-4f75-aef7-3d60e2f833bf",
   "metadata": {},
   "source": [
    "## Improved Model 1 Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a307d-4bd9-4c05-82fa-e4c4ea2de482",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(improved_model_one, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2d661-5a01-4a2a-a435-978cffd63a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_one.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca8f71-3472-4d3c-acd8-b740e6af978c",
   "metadata": {},
   "source": [
    "## Improved Model 1 Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae5fdd-b0fb-4722-b022-e3d609df4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(improved_model_one_pt2, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e5a64-e2ad-4c39-b966-ad1d92903a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_one_pt2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47be96e-f740-4b5d-a20f-62efd5e307ad",
   "metadata": {},
   "source": [
    "## Improved Model 1 Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343d1b6-ab46-48f2-a67f-1953386b4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(improved_model_pt3, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a220b-466e-47c2-b8b1-f9101ab28815",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model_pt3.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
