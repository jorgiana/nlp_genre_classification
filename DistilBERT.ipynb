{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e6da3-3a50-47ca-ba3c-897ae01609e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from utils import Attention\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf194d-575e-4e87-a1a1-127f4e886ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_to_numbers(arr):\n",
    "    output = []\n",
    "    for genre in arr:\n",
    "        if genre == \"country\": output.append(0)\n",
    "        elif genre == \"pop\": output.append(1)\n",
    "        elif genre == \"r-b\": output.append(2)\n",
    "        elif genre == \"rock\": output.append(3)\n",
    "        elif genre == \"rap\": output.append(4)\n",
    "    return output\n",
    "\n",
    "def remove_duplicate_words(string):\n",
    "    temp = string.split()\n",
    "    \n",
    "    return \" \".join(sorted(set(temp), key=temp.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9d69e-fac2-407e-83fe-75321e3ad1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train-lyrics.csv')\n",
    "test_df = pd.read_csv('test-lyrics.csv')\n",
    "\n",
    "joined_genres = pd.concat([train_df['genre'], test_df['genre']]).reset_index(drop=True)\n",
    "cat_labels = []\n",
    "for genre in joined_genres:\n",
    "    if genre == \"country\": cat_labels.append(0)\n",
    "    elif genre == \"pop\": cat_labels.append(1)\n",
    "    elif genre == \"r-b\": cat_labels.append(2)\n",
    "    elif genre == \"rock\": cat_labels.append(3)\n",
    "    elif genre == \"rap\": cat_labels.append(4)\n",
    "\n",
    "texts = pd.concat([train_df['input texts'], test_df['input texts']]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "semicleaned_input_texts = texts.str.replace(\"``\", \"\")\\\n",
    "                   .str.replace(\"\"\"''\"\"\", \"\")\\\n",
    "                   .str.replace(\"(\", \"\")\\\n",
    "                   .str.replace(\"â€™\", \"\")\\\n",
    "                   .str.replace(\")\", \"\")\n",
    "\n",
    "num_labels = len(test_df['genre'].value_counts())\n",
    "new_d = {'genre':joined_genres, 'sem texts':semicleaned_input_texts}\n",
    "df = pd.DataFrame(new_d)\n",
    "df['texts'] = df['sem texts'].apply(remove_duplicate_words)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13046708-5267-4f54-aeff-32900687e7df",
   "metadata": {},
   "source": [
    "# Model Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778df63-deea-409e-9d61-062d66d50017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(create_fn, \n",
    "              epochs=20, \n",
    "              batch_size=20, \n",
    "              **kwargs):\n",
    "    \n",
    "    model = create_fn(kwargs)\n",
    "    \n",
    "    history = model.fit([bert_x_train_tokenized.input_ids, \n",
    "                         bert_x_train_tokenized.attention_mask], \n",
    "                         y_train, \n",
    "                         validation_data=([\n",
    "                               bert_x_test_tokenized.input_ids, \n",
    "                               bert_x_test_tokenized.attention_mask], y_test), \n",
    "                           epochs = epochs, \n",
    "                           batch_size = batch_size)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d2f31-75da-4adf-83dc-7703b4bba397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_training_df(history_dict, num_epochs):\n",
    "    epochs_index = pd.Index(data=list(range(1, num_epochs + 1)), name=\"epoch\")\n",
    "    out_df = pd.DataFrame(history_dict).set_index(epochs_index)\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "def plot_model_performance(df, model_num):\n",
    "    \n",
    "    df_one = df[['loss', 'val_loss']]\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.lineplot(data=df_one)\n",
    "    plt.title(f\"Model {model_num} Loss by Epochs\");\n",
    "    plt.show();\n",
    "    \n",
    "    df_two = df[['accuracy', 'val_accuracy']]\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    sns.lineplot(data=df_two)\n",
    "    plt.title(f\"Model {model_num} Accuracy by Epochs\");\n",
    "    plt.show();\n",
    "    \n",
    "    \n",
    "def evaluate_model(model):\n",
    "    \n",
    "    return model.evaluate(bert_x_test_tokenized.input_ids, \n",
    "                          bert_x_test_tokenized.attention_mask,\n",
    "                          y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cc90a-966f-4484-b83b-71e598a9a6f4",
   "metadata": {},
   "source": [
    "## Huggingface BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a787c6-f519-428b-8b96-c0e573216a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (DistilBertTokenizer, TFDistilBertModel, DistilBertConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f2173-a7ba-4932-af34-4412242a5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd090c-f09b-4008-bea3-70588abadafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    del bert \n",
    "except: \n",
    "    pass\n",
    "\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-cased\", \n",
    "                                          output_hidden_states=True,\n",
    "                                          output_attentions=True, \n",
    "                                          return_dict=False)\n",
    "bert = TFDistilBertModel.from_pretrained('distilbert-base-cased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53cec4-3b26-4a89-951f-e71244ece57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['texts'],\n",
    "                                                    df['genre'], \n",
    "                                                    stratify=df['genre'])\n",
    "\n",
    "bert_X_train = X_train.to_list()\n",
    "bert_X_test = X_test.to_list()\n",
    "bert_y_train = genre_to_numbers(y_train)\n",
    "bert_y_test = genre_to_numbers(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(bert_y_train)\n",
    "y_test = tf.keras.utils.to_categorical(bert_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869c6e9-cb9f-4324-b9e8-a13d662bc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb5e9a-4c86-485a-aff7-538e0ca02786",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "bert_x_train_tokenized = tokenizer(bert_X_train, \n",
    "                                   max_length=MAX_SEQUENCE_LENGTH, \n",
    "                                   add_special_tokens=False,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length', \n",
    "                                   return_tensors=\"tf\")\n",
    "\n",
    "bert_x_test_tokenized = tokenizer(bert_X_test, \n",
    "                                  max_length=MAX_SEQUENCE_LENGTH, \n",
    "                                  add_special_tokens=False,\n",
    "                                  truncation=True, \n",
    "                                  padding='max_length',\n",
    "                                  return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc039562-716b-435a-a3e0-b822e8581de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                                metrics=[\"accuracy\"]):\n",
    "    \n",
    "    input_ids = layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "                             dtype=tf.int32)\n",
    "    attention_mask = layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "                                  dtype=tf.int32)\n",
    "    \n",
    "    bert_inputs = {\n",
    "        'input_ids': input_ids, \n",
    "        'attention_mask': attention_mask\n",
    "    }\n",
    "    \n",
    "    \n",
    "    bert_out = bert(input_ids=bert_inputs['input_ids'], \n",
    "                    attention_mask=bert_inputs['attention_mask'])[0]\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(64, activation=\"relu\")(bert_out)\n",
    "    \n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    \n",
    "    dropout = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels, activation='softmax')(dropout)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], \n",
    "                                          outputs=[classification])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f3b87-e56b-4722-baab-def8838b20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model, bert_model_history = fit_model(create_model, \n",
    "                                           epochs=10,\n",
    "                                           batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0ebb0-d01b-446d-ada9-6f57b6fbe2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_df = create_model_training_df(bert_model_history.history, 10)\n",
    "plot_model_performance(bert_model_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e753403-80a4-4031-b73a-f80f63474bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.evaluate([bert_x_test_tokenized.input_ids, bert_x_test_tokenized.attention_mask], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035dfff-6841-4ad9-a9c2-2d33a326dd4b",
   "metadata": {},
   "source": [
    "# DistilBERT Model W Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9398c-38cd-4ae7-9ffe-60bc5fb40cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    del bert \n",
    "except:\n",
    "    pass\n",
    "\n",
    "bert = TFDistilBertModel.from_pretrained('distilbert-base-cased', config=config)\n",
    "\n",
    "def create_model_pt2(hidden_size=100, \n",
    "                                train_layers=-1, \n",
    "                                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                                metrics=[\"accuracy\"]):\n",
    "    \n",
    "    input_ids = layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype=tf.int32)\n",
    "    attention_mask = layers.Input(shape=(MAX_SEQUENCE_LENGTH, ), dtype=tf.int32)\n",
    "    \n",
    "    bert_inputs = {\n",
    "        'input_ids': input_ids, \n",
    "        'attention_mask': attention_mask\n",
    "    }\n",
    "    \n",
    "    \n",
    "    bert_out = bert(input_ids=bert_inputs['input_ids'], \n",
    "                    attention_mask=bert_inputs['attention_mask'])[0]\n",
    "\n",
    "    \n",
    "    x, y, z = layers.LSTM(300, \n",
    "                          return_sequences=True, \n",
    "                          return_state=True)(bert_out)\n",
    "    \n",
    "    x, y = Attention(100)(x, y)\n",
    "    \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    classification = tf.keras.layers.Dense(num_labels, \n",
    "                                           activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], \n",
    "                           outputs=[classification])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915f44c-da98-4b5b-8160-407355ea40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_pt2, bert_model_pt2_history = fit_model(create_model_pt2, \n",
    "                                           train_layers=0,\n",
    "                                           epochs=10,\n",
    "                                           batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d3c4c-a455-4ae6-883c-035dccce8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_pt2_df = create_model_training_df(bert_model_pt2_history.history, 10)\n",
    "plot_model_performance(bert_model_pt2_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9d0d3-a451-4391-94e7-771736975642",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_pt2.evaluate([bert_x_test_tokenized.input_ids, bert_x_test_tokenized.attention_mask], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c94b7c-6923-477b-8909-d79ae0fdd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bert_model_pt2.predict([bert_x_test_tokenized.input_ids, bert_x_test_tokenized.attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91598712-00a9-43dd-b0c2-13d4ddb09e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "genre_lst = [\"country\", \"pop\", \"r-b\", \"rock\", \"rap\"]\n",
    "\n",
    "sns.heatmap(cm, cmap=\"Blues\", \n",
    "            xticklabels=genre_lst, \n",
    "            yticklabels=genre_lst)\n",
    "\n",
    "plt.title(\"Confusion Matrix\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
